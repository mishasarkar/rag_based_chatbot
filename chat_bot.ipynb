{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import fitz  # PyMuPDF\n",
    "# import a chain from langchain.chains\n",
    "from langchain.chains import ConversationChain\n",
    "# from langchain.chains import SimpleChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up your OpenAI API key\n",
    "openai.api_key = 'xx-xxxx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract text from a PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Extracts all text from a PDF file.\n",
    "    \"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc.load_page(page_num)\n",
    "        text += page.get_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = 'star_signs.pdf'\n",
    "context = extract_text_from_pdf(pdf_path)\n",
    "# print the first 1000 characters of the text\n",
    "print(context[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed-size chunking method\n",
    "def fixed_size_chunking(text, chunk_size=512):\n",
    "    \"\"\"\n",
    "    Splits text into fixed-size chunks based on a specified chunk size.\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    chunks = [' '.join(words[i:i+chunk_size]) for i in range(0, len(words), chunk_size)]\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = fixed_size_chunking(context)  # Chunk the extracted text\n",
    "# print the first chunk\n",
    "print(chunks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic retrieval method using TF-IDF\n",
    "def retrieve_relevant_chunks(chunks, query, top_k=3):\n",
    "    \"\"\"\n",
    "    Retrieves the most relevant chunks based on the user's query using TF-IDF.\n",
    "    \"\"\"\n",
    "    vectorizer = TfidfVectorizer().fit_transform(chunks)\n",
    "    query_vec = vectorizer.transform([query])\n",
    "    similarity = cosine_similarity(query_vec, vectorizer).flatten()\n",
    "    relevant_indices = similarity.argsort()[-top_k:][::-1]\n",
    "    relevant_chunks = [chunks[i] for i in relevant_indices]\n",
    "    return relevant_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentence-based chunking method\n",
    "def sentence_based_chunking(text):\n",
    "    \"\"\"\n",
    "    Splits text into sentences using regular expressions.\n",
    "    \"\"\"\n",
    "    sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', text)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the response function\n",
    "def get_openai_response(prompt):\n",
    "    \"\"\"\n",
    "    This function sends a prompt to the OpenAI API and retrieves the response.\n",
    "    \"\"\"\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"gpt-4o\",  # The model to use\n",
    "        prompt=prompt,              # The prompt containing the user input\n",
    "        max_tokens=150,             # The maximum number of tokens to generate\n",
    "        n=1,                        # Number of responses to generate\n",
    "        stop=None,                  # Stop sequence for the model\n",
    "        temperature=0.7,            # Sampling temperature for response generation\n",
    "    )\n",
    "    return response.choices[0].text.strip()  # Return the generated response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a prompt template that includes the context\n",
    "prompt_template = PromptTemplate(template=\"Context: {context}\\n\\nThe user says: {input}\\nAI assistant replies:\", input_variables=[\"context\", \"input\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a conversation chain class\n",
    "class OpenAIChatbotChain(ConversationChain):\n",
    "    def __init__(self, prompt_template, chunks):\n",
    "        self.chunks = chunks\n",
    "        self.prompt_template = prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\"OpenAIChatbotChain\" object has no field \"chunks\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create a conversation chain instance\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m chatbot_chain \u001b[38;5;241m=\u001b[39m OpenAIChatbotChain(prompt_template, chunks)\n",
      "Cell \u001b[0;32mIn[43], line 4\u001b[0m, in \u001b[0;36mOpenAIChatbotChain.__init__\u001b[0;34m(self, prompt_template, chunks)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, prompt_template, chunks):\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunks \u001b[38;5;241m=\u001b[39m chunks\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprompt_template \u001b[38;5;241m=\u001b[39m prompt_template\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ds_env/lib/python3.12/site-packages/pydantic/v1/main.py:357\u001b[0m, in \u001b[0;36mBaseModel.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m object_setattr(\u001b[38;5;28mself\u001b[39m, name, value)\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__config__\u001b[38;5;241m.\u001b[39mextra \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Extra\u001b[38;5;241m.\u001b[39mallow \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__fields__:\n\u001b[0;32m--> 357\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m object has no field \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__config__\u001b[38;5;241m.\u001b[39mallow_mutation \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__config__\u001b[38;5;241m.\u001b[39mfrozen:\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is immutable and does not support item assignment\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: \"OpenAIChatbotChain\" object has no field \"chunks\""
     ]
    }
   ],
   "source": [
    "# Create a conversation chain instance\n",
    "chatbot_chain = OpenAIChatbotChain(prompt_template, chunks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
